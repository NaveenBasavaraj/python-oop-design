# ğŸ§  Concurrency

> **Concurrency = doing multiple things at the same time (or appearing to).**  
> Goal: **better CPU usage, less waiting, faster programs**.

---

## 1ï¸âƒ£ Why Concurrency Exists (Reality Check)

### âŒ Sequential programs are dumbly slow

Task A â†’ Task B â†’ Task C â†’ Done
````

Problems:

* Uses **only one CPU core**
* Wastes time **waiting for I/O** (network, disk, DB)
* Modern CPUs have **multiple cores** sitting idle

### âœ… Concurrency fixes this

```text
Task A â”
Task B â”œâ†’ Done faster
Task C â”˜
```

---

## 2ï¸âƒ£ CPU-bound vs I/O-bound (CRITICAL DISTINCTION)

### CPU-bound

* Heavy calculations
* Math, compression, ML, cryptography
* **Needs more CPU cores**

### I/O-bound

* Waiting for network, disk, DB, APIs
* CPU mostly idle
* **Needs better scheduling**

> **This distinction decides which concurrency model to use.**

---

## 3ï¸âƒ£ Multiprocessing ğŸ§© (True Parallelism)

### What it is

* Multiple **processes**
* Each process has:

  * Its **own memory**
  * Its **own Python interpreter**
  * Runs on **different CPU cores**

### Mental Model

```text
CPU Core 1 â†’ Process A
CPU Core 2 â†’ Process B
CPU Core 3 â†’ Process C
CPU Core 4 â†’ Process D
```

### Characteristics

* âœ… True parallel execution
* âŒ Heavy memory usage
* âŒ Inter-process communication is slow
* âŒ Process creation is expensive

### When to use

âœ” CPU-bound work
âœ” Data processing
âœ” ML training
âœ” Image/video processing

### Python example (conceptual)

```python
from multiprocessing import Process

def work():
    print("Heavy computation")

p1 = Process(target=work)
p2 = Process(target=work)

p1.start()
p2.start()
```

### Brutal truth

> Multiprocessing is **powerful but expensive**.
> Use only when CPU is your bottleneck.

---

## 4ï¸âƒ£ Multithreading ğŸ§µ (Illusion of Parallelism in Python)

### What it is

* Multiple **threads** inside one process
* **Shared memory**
* Lightweight compared to processes

### Mental Model

```text
Process
 â”œâ”€ Thread 1 (shared memory)
 â”œâ”€ Thread 2 (shared memory)
 â””â”€ Thread 3 (shared memory)
```

### Pythonâ€™s ugly truth: **GIL**

* **Global Interpreter Lock**
* Only **ONE thread executes Python bytecode at a time**

```text
Thread A â”€â”
Thread B â”€â”¼â”€ GIL â”€ CPU
Thread C â”€â”˜
```

### So why threads exist at all?

Because while one thread is **waiting for I/O**, another can run.

### When threading works

âœ” I/O-bound tasks
âœ” Network calls
âœ” DB queries
âœ” File operations

### When threading FAILS

âŒ CPU-bound work (GIL kills parallelism)

### Example

```python
import threading

def fetch_data():
    print("Waiting for API")

t1 = threading.Thread(target=fetch_data)
t2 = threading.Thread(target=fetch_data)

t1.start()
t2.start()
```

### Danger zone

* Race conditions
* Deadlocks
* Shared state bugs

> Threads are **easy to start** and **hard to debug**.

---

## 5ï¸âƒ£ Asynchronous Programming âš¡ (Smart Waiting)

### What async actually means

> **Single thread, single process, multiple tasks cooperatively sharing time**

No parallel execution.
Just **non-blocking waiting**.

### Mental Model

```text
Event Loop
 â”œâ”€ Task A (waiting for network)
 â”œâ”€ Task B (runs)
 â”œâ”€ Task C (waiting for DB)
```

### Key idea

> Donâ€™t block.
> **Yield control when waiting.**

### ASCII Diagram

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Event Loop  â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”
  â”‚ Task1 â”‚   â”‚ Task2 â”‚
  â””â”€â”€â”€â”¬â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”˜
      â”‚ await     â”‚ await
      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
             â–¼
         Network / DB
```

### Example

```python
import asyncio

async def fetch():
    await asyncio.sleep(1)
    print("Fetched")

async def main():
    await asyncio.gather(fetch(), fetch(), fetch())

asyncio.run(main())
```

### Why async is powerful

* Handles **thousands of connections**
* Minimal memory
* No thread locks
* Perfect for servers

### When async SUCKS

âŒ CPU-heavy tasks
âŒ Blocking libraries
âŒ Complex logic (callback hell if abused)

---

## 6ï¸âƒ£ Comparison Table (Memorize This)

| Model           | Parallel?  | Best For    | Bad For     |
| --------------- | ---------- | ----------- | ----------- |
| Multiprocessing | âœ… Yes      | CPU-bound   | Memory, IPC |
| Multithreading  | âš ï¸ Limited | I/O-bound   | CPU-bound   |
| Async           | âŒ No       | Massive I/O | CPU work    |

---

## 7ï¸âƒ£ Web Server Example (FastAPI Mental Model)

### Bad (Blocking)

```text
Request â†’ DB wait â†’ Response
(others wait)
```

### Threaded

```text
Req1 â”€â”
Req2 â”€â”¼â”€ Threads
Req3 â”€â”˜
```

### Async (Best)

```text
Req1 (waiting)
Req2 (running)
Req3 (waiting)
```

> This is why **FastAPI + async** scales insanely well.

---

## 8ï¸âƒ£ Common Fallacies (Critical Thinking)

### âŒ â€œAsync is fasterâ€

Wrong.
Async is **less wasteful**, not faster at computation.

### âŒ â€œThreads use multiple coresâ€

In Python? Mostly **NO**.

### âŒ â€œMultiprocessing is always betterâ€

No.
IPC + memory overhead can make it slower.

---

## 9ï¸âƒ£ Decision Rule (Tattoo This)

```text
Is it CPU heavy?
  â†’ Multiprocessing

Is it I/O heavy but simple?
  â†’ Threading

Is it I/O heavy and scalable?
  â†’ Async
```

---

## 10ï¸âƒ£ Summary

* **Concurrency â‰  Parallelism**
* Python threads are **fake parallel**
* Async is **about waiting smartly**
* Multiprocessing is **real power, real cost**
* Choosing wrong model = wasted performance

---

